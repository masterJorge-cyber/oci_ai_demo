{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18553391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************Chat Result**************************\n",
      "{'status': 200, 'headers': {'content-type': 'application/json', 'opc-request-id': 'CDE7662741F14E99A85842F7E2C5BE61/38F23C08EE7784419B289D7AE09F5A34/C5533EC214054F98AB3902FEAC4B03BD', 'content-encoding': 'gzip', 'content-length': '308'}, 'data': {\n",
      "  \"chat_response\": {\n",
      "    \"api_format\": \"COHERE\",\n",
      "    \"chat_history\": [\n",
      "      {\n",
      "        \"message\": \"Quanto é 2+2? \",\n",
      "        \"role\": \"USER\"\n",
      "      },\n",
      "      {\n",
      "        \"message\": \"2+2 é igual a 4.\",\n",
      "        \"role\": \"CHATBOT\",\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    ],\n",
      "    \"citations\": null,\n",
      "    \"documents\": null,\n",
      "    \"error_message\": null,\n",
      "    \"finish_reason\": \"COMPLETE\",\n",
      "    \"is_search_required\": null,\n",
      "    \"prompt\": null,\n",
      "    \"search_queries\": null,\n",
      "    \"text\": \"2+2 é igual a 4.\",\n",
      "    \"tool_calls\": null,\n",
      "    \"usage\": {\n",
      "      \"completion_tokens\": 9,\n",
      "      \"completion_tokens_details\": null,\n",
      "      \"prompt_tokens\": 8,\n",
      "      \"prompt_tokens_details\": null,\n",
      "      \"total_tokens\": 17\n",
      "    }\n",
      "  },\n",
      "  \"model_id\": \"ocid1.generativeaimodel.oc1.sa-saopaulo-1.amaaaaaask7dceyaxu7lvx6k45r2hapxtuc2q5rleaujcowq6xbcywwtzhsq\",\n",
      "  \"model_version\": \"1.0\"\n",
      "}, 'request': <oci.request.Request object at 0x000001BB26C14D60>, 'next_page': None, 'request_id': 'CDE7662741F14E99A85842F7E2C5BE61/38F23C08EE7784419B289D7AE09F5A34/C5533EC214054F98AB3902FEAC4B03BD'}\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "# Copyright (c) 2023, Oracle and/or its affiliates.  All rights reserved.\n",
    "# This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.\n",
    "\n",
    "##########################################################################\n",
    "# chat_demo.py\n",
    "# Supports Python 3\n",
    "##########################################################################\n",
    "# Info:\n",
    "# Get texts from LLM model for given prompts using OCI Generative AI Service.\n",
    "##########################################################################\n",
    "# Application Command line(no parameter needed)\n",
    "# python chat_demo.py\n",
    "##########################################################################\n",
    "import oci\n",
    "\n",
    "# Setup basic variables\n",
    "# Auth Config\n",
    "# TODO: Please update config profile name and use the compartmentId that has policies grant permissions for using Generative AI Service\n",
    "compartment_id = \"ocid1.tenancy.oc1..aaaaaaaay7wrfzujlx4mvoplgaqx3loejtkgfdalq5g5loma2vbnna4if46a\"\n",
    "CONFIG_PROFILE = \"DEFAULT\"\n",
    "config = oci.config.from_file('~/.oci/config.txt', CONFIG_PROFILE)\n",
    "\n",
    "# Service endpoint\n",
    "endpoint = \"https://inference.generativeai.sa-saopaulo-1.oci.oraclecloud.com\"\n",
    "\n",
    "generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(config=config, service_endpoint=endpoint, retry_strategy=oci.retry.NoneRetryStrategy(), timeout=(10,240))\n",
    "chat_detail = oci.generative_ai_inference.models.ChatDetails()\n",
    "\n",
    "chat_request = oci.generative_ai_inference.models.CohereChatRequest()\n",
    "chat_request.message = \"Quanto é 2+2? \"\n",
    "chat_request.max_tokens = 600\n",
    "chat_request.temperature = 1\n",
    "chat_request.frequency_penalty = 0\n",
    "chat_request.top_p = 0.75\n",
    "chat_request.top_k = 0\n",
    "\n",
    "chat_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=\"ocid1.generativeaimodel.oc1.sa-saopaulo-1.amaaaaaask7dceyaxu7lvx6k45r2hapxtuc2q5rleaujcowq6xbcywwtzhsq\")\n",
    "chat_detail.chat_request = chat_request\n",
    "chat_detail.compartment_id = compartment_id\n",
    "\n",
    "chat_response = generative_ai_inference_client.chat(chat_detail)\n",
    "\n",
    "# Print result\n",
    "print(\"**************************Chat Result**************************\")\n",
    "print(vars(chat_response))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
